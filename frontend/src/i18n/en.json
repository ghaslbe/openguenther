{
  "topbar": {
    "light": "LIGHT",
    "dark": "DARK"
  },
  "chatList": {
    "newChatTitle": "New chat",
    "deleteChatTitle": "Delete chat",
    "empty": "No chats yet",
    "settings": "Settings"
  },
  "chat": {
    "welcome": "Welcome to Guenther!",
    "welcomeSub": "Send a message to get started.",
    "you": "You",
    "placeholder": "Type a message... or ask Guenther what he can do",
    "send": "Send",
    "copy": "Copy",
    "uploadFile": "Upload file",
    "startRecording": "Start voice input",
    "stopRecording": "Stop recording",
    "noAgent": "No agent (default)",
    "pdfDownload": "ðŸ“„ Download PDF",
    "pdfCreating": "Creating PDF...",
    "generatedImage": "Generated image",
    "presentation": "Presentation",
    "pptxDownload": "download"
  },
  "guenther": {
    "clearTitle": "Clear terminal",
    "waiting": "Waiting for activity...",
    "lines": "lines"
  },
  "toolSettings": {
    "saved": "Saved!",
    "saving": "Saving...",
    "save": "Save",
    "show": "Show",
    "hide": "Hide"
  },
  "settings": {
    "title": "Settings",
    "close": "Close",
    "nav": {
      "general": "General",
      "agents": "Agents",
      "autoprompts": "Autoprompts",
      "providers": "LLM Providers",
      "tools": "MCP Tools",
      "mcp": "MCP Servers",
      "webhooks": "Webhooks",
      "telegram": "Telegram",
      "hilfe": "Help",
      "info": "Info"
    },
    "sections": {
      "general": "General",
      "agents": "Agents",
      "autoprompts": "Autoprompts",
      "providers": "LLM Providers",
      "tools": "Built-in MCP Tools",
      "mcp": "External MCP Servers",
      "webhooks": "Webhooks",
      "telegram": "Telegram Gateway",
      "hilfe": "Help",
      "info": "Info"
    },
    "info": {
      "description": "Open-source AI agent with MCP tool support, self-hosted via Docker.",
      "disclaimer": "Disclaimer",
      "disclaimerText1": "This software is provided without any warranty. Use it entirely at your own risk.",
      "disclaimerText2": "The author accepts no liability whatsoever â€” neither for direct nor indirect damages, data loss, security incidents, costs incurred through third-party API usage (OpenRouter, OpenAI, etc.), damages from AI-generated content, or faulty tool executions.",
      "disclaimerText3": "Set spending limits on API keys. Do not enter sensitive data in chats. Do not expose the software publicly without authentication."
    },
    "general": {
      "llmSection": "LLM",
      "defaultProvider": "Default provider",
      "defaultProviderHelp": "Which provider is used by default for chat",
      "defaultModel": "Default model",
      "load": "Load",
      "noModels": "No models found",
      "loadError": "Error loading models",
      "selectModel": "â€” Select model from list â€”",
      "modelHelp": "e.g. openai/gpt-4o, anthropic/claude-3.5-sonnet, llama3.2 â€” depends on provider",
      "modelTipTitle": "Model selection is critical",
      "modelTipText": "The chosen model fundamentally determines how reliably tools are executed, tasks are understood, and results are structured. A solid starting point is openai/gpt-4.1-mini via OpenRouter â€” capable, fast, and cost-effective. From there, it's easy to experiment further.",
      "temperature": "Creativity (Temperature)",
      "tempExact": "Precise (0.1) â€” exact, deterministic",
      "tempMid": "Balanced (0.5) â€” balanced",
      "tempFree": "Creative (0.8) â€” creative, variable",
      "temperatureHelp": "Determines how creative / unpredictable the responses are",
      "timeout": "LLM Timeout (seconds)",
      "timeoutHelp": "Maximum wait time for LLM responses â€” increase for slow local models (default: 120s)",
      "audioSection": "Audio / Speech",
      "useWhisper": "Use OpenAI Whisper for speech recognition (STT)",
      "openaiKey": "OpenAI API Key",
      "whisperHelp": "Uses whisper-1 â€” more reliable than OpenRouter for audio",
      "sttModel": "Speech-to-Text model via OpenRouter",
      "sttPlaceholder": "empty = use chat model ({{model}})",
      "ttsModel": "Text-to-Speech model (TTS)",
      "ttsPlaceholder": "empty = use chat model ({{model}})",
      "ttsModelHelp": "For voice output (future feature)",
      "save": "Save",
      "saving": "Saving...",
      "saved": "Saved!",
      "show": "Show",
      "hide": "Hide"
    },
    "agents": {
      "description": "Agents have their own system prompt. When starting a new chat, you can select an agent.",
      "configured": "Configured agents",
      "updated": "Agent updated!",
      "created": "Agent created!",
      "edit": "Edit",
      "delete": "Delete",
      "empty": "No agents configured",
      "editTitle": "Edit agent",
      "newTitle": "Create new agent",
      "name": "Name",
      "namePlaceholder": "e.g. Poet",
      "descField": "Short description",
      "optional": "(optional)",
      "descPlaceholder": "e.g. Answers in rhymes",
      "systemPrompt": "System prompt",
      "systemPromptPlaceholder": "e.g. Always answer in rhymes.",
      "providerOverride": "Provider (override)",
      "providerDefault": "â€” Default (global setting) â€”",
      "modelOverride": "Model (override)",
      "modelPlaceholder": "empty = use default model",
      "providerSelectFirst": "Select a provider first",
      "save": "Save",
      "create": "Create",
      "cancel": "Cancel",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "Agents exported!",
      "imported": "{{n}} agent(s) imported!",
      "importError": "Import failed"
    },
    "autoprompts": {
      "description": "Autoprompts run automatically at scheduled times. The result is saved in a dedicated chat in the history.",
      "configured": "Configured autoprompts",
      "deleteConfirm": "Really delete this autoprompt?",
      "running": "Running...",
      "updated": "Autoprompt updated!",
      "created": "Autoprompt created!",
      "chatLabel": "Chat",
      "silentLabel": "Silent",
      "lastRun": "Last run:",
      "success": "Success",
      "error": "Error",
      "log": "Log",
      "runNow": "Run now",
      "pause": "Pause",
      "activate": "Active",
      "edit": "Edit",
      "delete": "Delete",
      "empty": "No autoprompts configured",
      "editTitle": "Edit autoprompt",
      "newTitle": "Create new autoprompt",
      "name": "Name",
      "namePlaceholder": "e.g. Daily briefing",
      "prompt": "Prompt",
      "schedule": "Schedule",
      "scheduleInterval": "Interval (every X minutes/hours)",
      "scheduleDaily": "Daily at a specific time",
      "scheduleWeekly": "Weekly",
      "intervalMinutes": "Interval (minutes)",
      "weekday": "Weekday",
      "time": "Time (HH:MM, UTC)",
      "serverTime": "Current server time:",
      "agent": "Agent",
      "defaultAgent": "Default (no agent)",
      "enabled": "Enabled",
      "saveToChat": "Save result to chat",
      "saveToChatDesc": "Disabled: agent runs silently (e.g. Telegram only). Enabled: result is saved in a dedicated chat in the history.",
      "save": "Save",
      "create": "Create",
      "cancel": "Cancel",
      "close": "Close",
      "logTitle": "Log:",
      "errorTitle": "Error:",
      "weekdays": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"],
      "scheduleEveryH": "Every {{n}}h",
      "scheduleEveryMin": "Every {{n}} min",
      "scheduleWeeklyAt": "{{day}} {{time}} UTC",
      "scheduleDailyAt": "Daily {{time}} UTC",
      "promptPlaceholder": "e.g. Give me a summary of today's news and send it via Telegram to @mama75.\n\n(Note: The recipient must have messaged the bot at least once before, otherwise Telegram won't allow it.)",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "Autoprompts exported!",
      "imported": "{{n}} autoprompt(s) imported!",
      "importError": "Import failed"
    },
    "providers": {
      "description": "All providers are OpenAI API-compatible. No API key needed for Ollama and LM Studio.",
      "active": "Active",
      "inactive": "Inactive",
      "name": "Name",
      "baseUrl": "Base URL",
      "baseUrlHelp": "Ends with /v1 â€” /chat/completions is appended automatically",
      "apiKey": "API Key",
      "apiKeyOptional": "(optional)",
      "apiKeyHelp": "Only fill in to change the stored key",
      "noBaseUrl": "No base URL configured",
      "save": "Save",
      "saving": "Saving...",
      "saved": "Saved!",
      "testing": "Testing...",
      "test": "Test connection",
      "testOk_one": "âœ“ Connection OK â€” {{count}} model found",
      "testOk_other": "âœ“ Connection OK â€” {{count}} models found",
      "testErr": "âœ— Error: {{error}}",
      "show": "Show",
      "hide": "Hide",
      "sshTitle": "SSH tunnel (from home to server)",
      "sshDesc": "If {{label}} is running on your local machine, you can make it accessible to the server via SSH reverse tunnel. Run this command on your local machine:",
      "sshUrlTitle": "While the tunnel is active, enter this as the base URL:",
      "sshNote": "host.docker.internal points from the container to the server host where the SSH tunnel is listening. -N opens the tunnel only without a shell. For a persistent tunnel, autossh is recommended.",
      "sshPrereqTitle": "Prerequisite: Configure SSH server",
      "sshPrereqDesc": "For the reverse tunnel to work, /etc/ssh/sshd_config on the server must contain:",
      "sshRestartDesc": "GatewayPorts yes is needed so the forwarded port is not only accessible on 127.0.0.1 of the server but also from the Docker container. Then restart the SSH service:",
      "openrouterKeys": "API Keys at OpenRouter",
      "openrouterUsage": "Usage at OpenRouter",
      "mistralKeys": "API Keys at Mistral",
      "mistralUsage": "Usage at Mistral",
      "mistralDocs": "Mistral API documentation",
      "subtitles": {
        "openrouter": "via USA, models worldwide",
        "mistral": "Europe",
        "ollama": "local AI",
        "lmstudio": "local AI"
      }
    },
    "tools": {
      "description": "Per tool you can override the provider and model. If the override is set, it will be used for that tool.",
      "builtin": "Built-in",
      "external": "External",
      "builtinSection": "Built-in Tools",
      "externalSection": "External Tools",
      "noExternal": "No external MCP tools loaded",
      "override": "Override",
      "providerOverride": "Provider override",
      "modelOverride": "Model override",
      "useDefault": "Use default",
      "modelPlaceholder": "empty = use default model",
      "timeoutLabel": "Timeout (seconds)",
      "timeoutPlaceholder": "empty = default",
      "saving": "Saving...",
      "save": "Save",
      "savedMsg": "{{name}} saved!",
      "reloaded": "MCP tools reloaded!",
      "reloading": "Loading...",
      "reload": "Reload MCP tools",
      "show": "Show",
      "hide": "Hide"
    },
    "mcp": {
      "description": "External MCP servers are connected via stdio (JSON-RPC 2.0). After adding, click \"Reload MCP tools\" under Tools.",
      "configured": "Configured servers",
      "remove": "Remove",
      "empty": "No external MCP servers configured",
      "addTitle": "Add new server",
      "added": "Server added!",
      "saved": "Server saved!",
      "reloaded": "MCP tools reloaded!",
      "reloading": "Loading...",
      "reload": "Reload tools",
      "add": "Add",
      "edit": "Edit",
      "save": "Save",
      "cancel": "Cancel",
      "envPlaceholder": "Environment variables (optional, one per line):\nFIRECRAWL_API_KEY=fc-xxx\nOTHER_VAR=value",
      "marketplaceHint": "Find MCP servers on various marketplaces, e.g.",
      "marketplaceHintSuffix": " â€” one of many.",
      "toolsHint": "The tools from configured servers appear under \"MCP Tools\" after reloading.",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "MCP servers exported!",
      "imported": "{{n}} server(s) imported!",
      "importError": "Import failed"
    },
    "usage": {
      "title": "Usage statistics",
      "today": "Today",
      "week": "Week",
      "month": "Month",
      "all": "Total",
      "requests": "Requests",
      "sent": "Sent",
      "received": "Received",
      "tokens": "Tokens",
      "provider": "Provider",
      "model": "Model",
      "noData": "No data for this period",
      "reset": "Reset statistics",
      "resetConfirm": "Really delete all statistics?",
      "resetCancel": "Cancel"
    },
    "webhooks": {
      "description": "Webhooks allow external systems to trigger OpenGuenther via HTTP â€” e.g. from home automation, scripts, or other apps.",
      "info": "Each webhook has its own Bearer token. Optionally set a fixed chat ID to preserve context across calls. Without a chat ID, a new chat is created for every request.",
      "configured": "Configured webhooks",
      "empty": "No webhooks configured",
      "newTitle": "Create new webhook",
      "name": "Name",
      "namePlaceholder": "e.g. Home automation",
      "optional": "optional",
      "chatId": "Chat ID",
      "chatIdPlaceholder": "empty = new chat per request",
      "chatIdHelp": "ID of an existing chat from the sidebar. Leave empty to create a new chat for every request.",
      "newChatEach": "New chat per request",
      "agent": "Agent",
      "noAgent": "No agent (default)",
      "token": "Token",
      "copy": "Copy",
      "copied": "âœ“",
      "showCurl": "Show cURL example",
      "hideCurl": "Hide cURL example",
      "edit": "Edit",
      "delete": "Delete",
      "deleteConfirm": "Really delete this webhook?",
      "save": "Save",
      "cancel": "Cancel",
      "create": "Create",
      "created": "Webhook created!",
      "updated": "Webhook updated!"
    },
    "telegram": {
      "gatewayStatus": "Gateway status:",
      "active": "ACTIVE",
      "stopped": "STOPPED",
      "configSection": "Configuration",
      "botToken": "Bot token",
      "botTokenHelp": "Bot token from @BotFather",
      "allowedUsers": "Allowed users (one username per line, without @)",
      "allowedUsersHelp": "Only these Telegram usernames may send messages",
      "saved": "Telegram settings saved!",
      "saving": "Saving...",
      "save": "Save",
      "starting": "Starting Telegram gateway...",
      "started": "Telegram gateway started!",
      "startError": "Error: {{error}}",
      "stoppedMsg": "Telegram gateway stopped.",
      "restart": "Start / restart gateway",
      "stop": "Stop gateway",
      "show": "Show",
      "hide": "Hide"
    }
  },
  "firstRun": {
    "welcome": "Willkommen",
    "subtitle": "WÃ¤hle deine Sprache / Choose your language",
    "langDe": "Deutsch",
    "langEn": "English",
    "requirementTitle": "Voraussetzung / Requirement",
    "requirementDe": "Du benÃ¶tigst einen der folgenden ZugÃ¤nge:",
    "requirementEn": "You need one of the following:",
    "option1De": "OpenRouter API Key (empfohlen) â€” viele Modelle, einfache Einrichtung",
    "option1En": "OpenRouter API Key (recommended) â€” many models, easy setup",
    "option2De": "Ollama â€” lokal auf deinem Rechner / Server",
    "option2En": "Ollama â€” running locally on your machine / server",
    "option3De": "LM Studio â€” lokal mit OpenAI-kompatibler API",
    "option3En": "LM Studio â€” locally with OpenAI-compatible API",
    "openrouterDe": "OpenRouter API Key holen",
    "openrouterEn": "Get OpenRouter API Key",
    "continueDe": "Weiter",
    "continueEn": "Continue"
  }
}
