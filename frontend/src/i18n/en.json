{
  "topbar": {
    "light": "LIGHT",
    "dark": "DARK"
  },
  "chatList": {
    "newChatTitle": "New chat",
    "deleteChatTitle": "Delete chat",
    "empty": "No chats yet",
    "settings": "Settings"
  },
  "chat": {
    "welcome": "Welcome to Guenther!",
    "welcomeSub": "Send a message to get started.",
    "you": "You",
    "placeholder": "Type a message... or ask Guenther what he can do",
    "send": "Send",
    "stop": "Stop",
    "copy": "Copy",
    "uploadFile": "Upload file",
    "startRecording": "Start voice input",
    "stopRecording": "Stop recording",
    "noAgent": "No agent (default)",
    "pdfDownload": "üìÑ Download PDF",
    "pdfCreating": "Creating PDF...",
    "generatedImage": "Generated image",
    "presentation": "Presentation",
    "pptxDownload": "download"
  },
  "guenther": {
    "clearTitle": "Clear terminal",
    "waiting": "Waiting for activity...",
    "lines": "lines"
  },
  "toolSettings": {
    "saved": "Saved!",
    "saving": "Saving...",
    "save": "Save",
    "show": "Show",
    "hide": "Hide"
  },
  "settings": {
    "title": "Settings",
    "close": "Close",
    "nav": {
      "general": "General",
      "agents": "Agents",
      "autoprompts": "Autoprompts",
      "providers": "LLM Providers",
      "tools": "MCP Tools",
      "mcp": "MCP Servers",
      "webhooks": "Webhooks",
      "telegram": "Telegram",
      "hilfe": "Help",
      "info": "Info"
    },
    "sections": {
      "general": "General",
      "agents": "Agents",
      "autoprompts": "Autoprompts",
      "providers": "LLM Providers",
      "tools": "Built-in MCP Tools",
      "mcp": "External MCP Servers",
      "webhooks": "Webhooks",
      "telegram": "Telegram Gateway",
      "hilfe": "Help",
      "info": "Info"
    },
    "info": {
      "description": "Open-source AI agent with MCP tool support, self-hosted via Docker.",
      "disclaimer": "Disclaimer",
      "disclaimerText1": "This software is provided without any warranty. Use it entirely at your own risk.",
      "disclaimerText2": "The author accepts no liability whatsoever ‚Äî neither for direct nor indirect damages, data loss, security incidents, costs incurred through third-party API usage (OpenRouter, OpenAI, etc.), damages from AI-generated content, or faulty tool executions.",
      "disclaimerText3": "Set spending limits on API keys. Do not enter sensitive data in chats. Do not expose the software publicly without authentication."
    },
    "general": {
      "llmSection": "LLM",
      "defaultProvider": "Default provider",
      "defaultProviderHelp": "Which provider is used by default for chat",
      "defaultModel": "Default model",
      "load": "Load",
      "noModels": "No models found",
      "loadError": "Error loading models",
      "selectModel": "‚Äî Select model from list ‚Äî",
      "modelHelp": "e.g. openai/gpt-4o, anthropic/claude-3.5-sonnet, llama3.2 ‚Äî depends on provider",
      "modelTipTitle": "Model selection is critical",
      "modelTipText": "The chosen model fundamentally determines how reliably tools are executed, tasks are understood, and results are structured. A solid starting point is openai/gpt-4.1-mini via OpenRouter ‚Äî capable, fast, and cost-effective. From there, it's easy to experiment further.",
      "temperature": "Creativity (Temperature)",
      "tempExact": "Precise (0.1) ‚Äî exact, deterministic",
      "tempMid": "Balanced (0.5) ‚Äî balanced",
      "tempFree": "Creative (0.8) ‚Äî creative, variable",
      "temperatureHelp": "Determines how creative / unpredictable the responses are",
      "timeout": "LLM Timeout (seconds)",
      "timeoutHelp": "Maximum wait time for LLM responses ‚Äî increase for slow local models (default: 120s)",
      "audioSection": "Audio / Speech",
      "useWhisper": "Use OpenAI Whisper for speech recognition (STT)",
      "openaiKey": "OpenAI API Key",
      "whisperHelp": "Uses whisper-1 ‚Äî more reliable than OpenRouter for audio",
      "sttModel": "Speech-to-Text model via OpenRouter",
      "sttPlaceholder": "empty = use chat model ({{model}})",
      "ttsModel": "Text-to-Speech model (TTS)",
      "ttsPlaceholder": "empty = use chat model ({{model}})",
      "ttsModelHelp": "For voice output (future feature)",
      "save": "Save",
      "saving": "Saving...",
      "saved": "Saved!",
      "show": "Show",
      "hide": "Hide"
    },
    "agents": {
      "description": "Agents have their own system prompt. When starting a new chat, you can select an agent.",
      "configured": "Configured agents",
      "updated": "Agent updated!",
      "created": "Agent created!",
      "edit": "Edit",
      "delete": "Delete",
      "empty": "No agents configured",
      "editTitle": "Edit agent",
      "newTitle": "Create new agent",
      "name": "Name",
      "namePlaceholder": "e.g. Poet",
      "descField": "Short description",
      "optional": "(optional)",
      "descPlaceholder": "e.g. Answers in rhymes",
      "systemPrompt": "System prompt",
      "systemPromptPlaceholder": "e.g. Always answer in rhymes.",
      "providerOverride": "Provider (override)",
      "providerDefault": "‚Äî Default (global setting) ‚Äî",
      "modelOverride": "Model (override)",
      "modelPlaceholder": "empty = use default model",
      "providerSelectFirst": "Select a provider first",
      "save": "Save",
      "create": "Create",
      "cancel": "Cancel",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "Agents exported!",
      "imported": "{{n}} agent(s) imported!",
      "importError": "Import failed"
    },
    "autoprompts": {
      "description": "Autoprompts run automatically at scheduled times. The result is saved in a dedicated chat in the history.",
      "configured": "Configured autoprompts",
      "deleteConfirm": "Really delete this autoprompt?",
      "running": "Running...",
      "updated": "Autoprompt updated!",
      "created": "Autoprompt created!",
      "chatLabel": "Chat",
      "silentLabel": "Silent",
      "lastRun": "Last run:",
      "success": "Success",
      "error": "Error",
      "log": "Log",
      "runNow": "Run now",
      "pause": "Pause",
      "activate": "Active",
      "edit": "Edit",
      "delete": "Delete",
      "empty": "No autoprompts configured",
      "editTitle": "Edit autoprompt",
      "newTitle": "Create new autoprompt",
      "name": "Name",
      "namePlaceholder": "e.g. Daily briefing",
      "prompt": "Prompt",
      "schedule": "Schedule",
      "scheduleInterval": "Interval (every X minutes/hours)",
      "scheduleDaily": "Daily at a specific time",
      "scheduleWeekly": "Weekly",
      "intervalMinutes": "Interval (minutes)",
      "weekday": "Weekday",
      "time": "Time (HH:MM, UTC)",
      "serverTime": "Current server time:",
      "agent": "Agent",
      "defaultAgent": "Default (no agent)",
      "enabled": "Enabled",
      "saveToChat": "Save result to chat",
      "saveToChatDesc": "Disabled: agent runs silently (e.g. Telegram only). Enabled: result is saved in a dedicated chat in the history.",
      "save": "Save",
      "create": "Create",
      "cancel": "Cancel",
      "close": "Close",
      "logTitle": "Log:",
      "errorTitle": "Error:",
      "weekdays": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"],
      "scheduleEveryH": "Every {{n}}h",
      "scheduleEveryMin": "Every {{n}} min",
      "scheduleWeeklyAt": "{{day}} {{time}} UTC",
      "scheduleDailyAt": "Daily {{time}} UTC",
      "promptPlaceholder": "e.g. Give me a summary of today's news and send it via Telegram to @mama75.\n\n(Note: The recipient must have messaged the bot at least once before, otherwise Telegram won't allow it.)",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "Autoprompts exported!",
      "imported": "{{n}} autoprompt(s) imported!",
      "importError": "Import failed"
    },
    "providers": {
      "description": "All providers are OpenAI API-compatible. No API key needed for Ollama and LM Studio.",
      "active": "Active",
      "inactive": "Inactive",
      "name": "Name",
      "baseUrl": "Base URL",
      "baseUrlHelp": "Ends with /v1 ‚Äî /chat/completions is appended automatically",
      "apiKey": "API Key",
      "apiKeyOptional": "(optional)",
      "apiKeyHelp": "Only fill in to change the stored key",
      "noBaseUrl": "No base URL configured",
      "save": "Save",
      "saving": "Saving...",
      "saved": "Saved!",
      "testing": "Testing...",
      "test": "Test connection",
      "testOk_one": "‚úì Connection OK ‚Äî {{count}} model found",
      "testOk_other": "‚úì Connection OK ‚Äî {{count}} models found",
      "testErr": "‚úó Error: {{error}}",
      "show": "Show",
      "hide": "Hide",
      "sshTitle": "SSH tunnel (from home to server)",
      "sshDesc": "If {{label}} is running on your local machine, you can make it accessible to the server via SSH reverse tunnel. Run this command on your local machine:",
      "sshUrlTitle": "While the tunnel is active, enter this as the base URL:",
      "sshNote": "host.docker.internal points from the container to the server host where the SSH tunnel is listening. -N opens the tunnel only without a shell. For a persistent tunnel, autossh is recommended.",
      "sshPrereqTitle": "Prerequisite: Configure SSH server",
      "sshPrereqDesc": "For the reverse tunnel to work, /etc/ssh/sshd_config on the server must contain:",
      "sshRestartDesc": "GatewayPorts yes is needed so the forwarded port is not only accessible on 127.0.0.1 of the server but also from the Docker container. Then restart the SSH service:",
      "openrouterKeys": "API Keys at OpenRouter",
      "openrouterUsage": "Usage at OpenRouter",
      "mistralKeys": "API Keys at Mistral",
      "mistralUsage": "Usage at Mistral",
      "mistralDocs": "Mistral API documentation",
      "subtitles": {
        "openrouter": "via USA, models worldwide",
        "mistral": "Europe",
        "ollama": "local AI",
        "lmstudio": "local AI"
      }
    },
    "tools": {
      "description": "Per tool you can override the provider and model. If the override is set, it will be used for that tool.",
      "builtin": "Built-in",
      "external": "External",
      "builtinSection": "Built-in Tools",
      "externalSection": "External Tools",
      "noExternal": "No external MCP tools loaded",
      "override": "Override",
      "providerOverride": "Provider override",
      "modelOverride": "Model override",
      "useDefault": "Use default",
      "modelPlaceholder": "empty = use default model",
      "timeoutLabel": "Timeout (seconds)",
      "timeoutPlaceholder": "empty = default",
      "saving": "Saving...",
      "save": "Save",
      "savedMsg": "{{name}} saved!",
      "reloaded": "MCP tools reloaded!",
      "reloading": "Loading...",
      "reload": "Reload MCP tools",
      "show": "Show",
      "hide": "Hide",
      "customSection": "Custom Tools",
      "customEmpty": "No custom tools installed",
      "customDownload": "ZIP Download",
      "customUpload": "ZIP Upload",
      "customUploaded": "Tool '{{name}}' installed!",
      "customUploadError": "Upload failed",
      "warnTitle": "‚ö†Ô∏è Security Warning",
      "warnText": "Custom tools are Python code that runs directly on the server. Only upload tools whose code you know and trust.\n\nA malicious tool can gain full access to the server ‚Äî including data, network, and filesystem.",
      "warnConfirm": "I understand ‚Äî Upload",
      "warnCancel": "Cancel"
    },
    "mcp": {
      "description": "External MCP servers are connected via stdio (JSON-RPC 2.0). After adding, click \"Reload MCP tools\" under Tools.",
      "configured": "Configured servers",
      "remove": "Remove",
      "empty": "No external MCP servers configured",
      "addTitle": "Add new server",
      "added": "Server added!",
      "saved": "Server saved!",
      "reloaded": "MCP tools reloaded!",
      "reloading": "Loading...",
      "reload": "Reload tools",
      "add": "Add",
      "edit": "Edit",
      "save": "Save",
      "cancel": "Cancel",
      "envPlaceholder": "Environment variables (optional, one per line):\nFIRECRAWL_API_KEY=fc-xxx\nOTHER_VAR=value",
      "marketplaceHint": "Find MCP servers on various marketplaces, e.g.",
      "marketplaceHintSuffix": " ‚Äî one of many.",
      "toolsHint": "The tools from configured servers appear under \"MCP Tools\" after reloading.",
      "export": "JSON Export",
      "import": "JSON Import",
      "exported": "MCP servers exported!",
      "imported": "{{n}} server(s) imported!",
      "importError": "Import failed"
    },
    "usage": {
      "title": "Usage statistics",
      "today": "Today",
      "week": "Week",
      "month": "Month",
      "all": "Total",
      "requests": "Requests",
      "sent": "Sent",
      "received": "Received",
      "tokens": "Tokens",
      "provider": "Provider",
      "model": "Model",
      "noData": "No data for this period",
      "reset": "Reset statistics",
      "resetConfirm": "Really delete all statistics?",
      "resetCancel": "Cancel"
    },
    "webhooks": {
      "description": "Webhooks allow external systems to trigger OpenGuenther via HTTP ‚Äî e.g. from home automation, scripts, or other apps.",
      "info": "Each webhook has its own Bearer token. Optionally set a fixed chat ID to preserve context across calls. Without a chat ID, a new chat is created for every request.",
      "configured": "Configured webhooks",
      "empty": "No webhooks configured",
      "newTitle": "Create new webhook",
      "name": "Name",
      "namePlaceholder": "e.g. Home automation",
      "optional": "optional",
      "chatId": "Chat ID",
      "chatIdPlaceholder": "empty = new chat per request",
      "chatIdHelp": "ID of an existing chat from the sidebar. Leave empty to create a new chat for every request.",
      "newChatEach": "New chat per request",
      "agent": "Agent",
      "noAgent": "No agent (default)",
      "token": "Token",
      "copy": "Copy",
      "copied": "‚úì",
      "showCurl": "Show cURL example",
      "hideCurl": "Hide cURL example",
      "edit": "Edit",
      "delete": "Delete",
      "deleteConfirm": "Really delete this webhook?",
      "save": "Save",
      "cancel": "Cancel",
      "create": "Create",
      "created": "Webhook created!",
      "updated": "Webhook updated!"
    },
    "telegram": {
      "gatewayStatus": "Gateway status:",
      "active": "ACTIVE",
      "stopped": "STOPPED",
      "configSection": "Configuration",
      "botToken": "Bot token",
      "botTokenHelp": "Bot token from @BotFather",
      "allowedUsers": "Allowed users (one username per line, without @)",
      "allowedUsersHelp": "Only these Telegram usernames may send messages",
      "saved": "Telegram settings saved!",
      "saving": "Saving...",
      "save": "Save",
      "starting": "Starting Telegram gateway...",
      "started": "Telegram gateway started!",
      "startError": "Error: {{error}}",
      "stoppedMsg": "Telegram gateway stopped.",
      "restart": "Start / restart gateway",
      "stop": "Stop gateway",
      "show": "Show",
      "hide": "Hide"
    }
  },
  "firstRun": {
    "welcome": "Willkommen",
    "subtitle": "W√§hle deine Sprache / Choose your language",
    "langDe": "Deutsch",
    "langEn": "English",
    "requirementTitle": "Voraussetzung / Requirement",
    "requirementDe": "Du ben√∂tigst einen der folgenden Zug√§nge:",
    "requirementEn": "You need one of the following:",
    "option1De": "OpenRouter API Key (empfohlen) ‚Äî viele Modelle, einfache Einrichtung",
    "option1En": "OpenRouter API Key (recommended) ‚Äî many models, easy setup",
    "option2De": "Ollama ‚Äî lokal auf deinem Rechner / Server",
    "option2En": "Ollama ‚Äî running locally on your machine / server",
    "option3De": "LM Studio ‚Äî lokal mit OpenAI-kompatibler API",
    "option3En": "LM Studio ‚Äî locally with OpenAI-compatible API",
    "openrouterDe": "OpenRouter API Key holen",
    "openrouterEn": "Get OpenRouter API Key",
    "continueDe": "Weiter",
    "continueEn": "Continue"
  }
}
